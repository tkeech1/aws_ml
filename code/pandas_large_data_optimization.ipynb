{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.dataquest.io/blog/pandas-big-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dask import dataframe as dd\n",
    "import numpy as np\n",
    "import featuretools as ft\n",
    "pd.set_option('display.width', 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank = pd.read_csv(\"../data/bank-additional-full.csv\",delimiter=\";\")\n",
    "# create a date field\n",
    "bank['date'] = '2020-01-25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the average memory usage for each data type\n",
    "for dtype in ['float','int','object']:\n",
    "    selected_dtype = bank.select_dtypes(include=[dtype])\n",
    "    mean_usage_b = selected_dtype.memory_usage(deep=True).mean()\n",
    "    mean_usage_mb = mean_usage_b / 1024 ** 2\n",
    "    print(\"Average memory usage for {} columns: {:03.2f} MB\".format(dtype,mean_usage_mb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) User smaller data types to hold numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the min and max values for each data type (or look it up)\n",
    "int_types = [\"uint8\", \"int8\", \"int16\"]\n",
    "for it in int_types:\n",
    "    print(np.iinfo(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to calculate memory usage\n",
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj,pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else: # we assume if not a df it's a series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downcast int types to reduce memory footprint\n",
    "bank_int = bank.select_dtypes(include=['int'])\n",
    "converted_int = bank_int.apply(pd.to_numeric,downcast='integer')\n",
    "print(mem_usage(bank_int))\n",
    "print(mem_usage(converted_int))\n",
    "compare_ints = pd.concat([bank_int.dtypes,converted_int.dtypes],axis=1)\n",
    "compare_ints.columns = ['before','after']\n",
    "compare_ints.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downcast float types to reduce memory footprint\n",
    "bank_float = bank.select_dtypes(include=['float'])\n",
    "converted_float = bank_float.apply(pd.to_numeric,downcast='float')\n",
    "print(mem_usage(bank_float))\n",
    "print(mem_usage(converted_float))\n",
    "compare_floats = pd.concat([bank_float.dtypes,converted_float.dtypes],axis=1)\n",
    "compare_floats.columns = ['before','after']\n",
    "compare_floats.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the original df and compare the optimizes very\n",
    "# compare the optimized to the original\n",
    "optimized_bank = bank.copy()\n",
    "optimized_bank[converted_bank.columns] = converted_bank\n",
    "optimized_bank[converted_float.columns] = converted_float\n",
    "print(mem_usage(bank))\n",
    "print(mem_usage(optimized_bank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Optimize objects using categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe all object types\n",
    "bank_obj = bank.select_dtypes(include=['object']).copy()\n",
    "bank_obj.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert a single feature to a category\n",
    "job = bank_obj.job\n",
    "print(job.head())\n",
    "job_cat = job.astype('category')\n",
    "print(job_cat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each unique value has been assigned an integer, and that the underlying datatype for the column is now int8. \n",
    "#This column doesn’t have any missing values, but if it did, the category subtype handles missing values by setting them to -1.\n",
    "job_cat.head(10).cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine the memory usage for the job feature before and after\n",
    "# The biggest drawback is the inability to perform numerical computations. \n",
    "# We can’t do arithmetic with category columns or use methods like Series.min() \n",
    "# and Series.max() without converting to a true numeric dtype first.\n",
    "\n",
    "print('Before {}'.format(mem_usage(job)))\n",
    "print('After {}'.format(mem_usage(job_cat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stick to using the category type primarily for object columns where less than 50% of the values are unique.\n",
    "converted_obj = pd.DataFrame()\n",
    "for col in bank_obj.columns:\n",
    "    num_unique_values = len(bank_obj[col].unique())\n",
    "    num_total_values = len(bank_obj[col])\n",
    "    if num_unique_values / num_total_values < 0.5:\n",
    "        converted_obj.loc[:,col] = bank_obj[col].astype('category')\n",
    "    else:\n",
    "        converted_obj.loc[:,col] = bank_obj[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check which features got converted to categories\n",
    "print(mem_usage(bank_obj))\n",
    "print(mem_usage(converted_obj))\n",
    "compare_obj = pd.concat([bank_obj.dtypes,converted_obj.dtypes],axis=1)\n",
    "compare_obj.columns = ['before','after']\n",
    "compare_obj.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the memory usage before and after\n",
    "optimized_bank[converted_obj.columns] = converted_obj\n",
    "print(mem_usage(bank))\n",
    "print(mem_usage(optimized_bank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Convert features to date/time when possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usage(bank['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = bank['date']\n",
    "optimized_bank['date'] = pd.to_datetime(date,format='%Y-%m-%d')\n",
    "optimized_bank.date.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mem_usage(bank['date']))\n",
    "print(mem_usage(optimized_bank['date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the memory usage before and after\n",
    "optimized_bank[converted_obj.columns] = converted_obj\n",
    "print(mem_usage(bank))\n",
    "print(mem_usage(optimized_bank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use types when reading the file from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_types = {\n",
    "    'age': 'uint8',\n",
    "    'job': 'category',\n",
    "    'marital': 'category',\n",
    "    'education': 'category',\n",
    "    'default': 'category',\n",
    "    'housing': 'category',\n",
    "    'loan': 'category',\n",
    "    'contact': 'category',\n",
    "    'month': 'category',\n",
    "    'day_of_week': 'category',\n",
    "    'duration': 'uint16',\n",
    "    'campaign': 'uint8',\n",
    "    'pdays': 'uint16',\n",
    "    'previous': 'uint8',\n",
    "    'poutcome': 'category',\n",
    "    'emp.var.rate': 'float32',\n",
    "    'cons.price.idx': 'float32',\n",
    "    'cons.conf.idx': 'float32',\n",
    "    'euribor3m': 'float32',\n",
    "    'nr.employed': 'float32',\n",
    "    'y': 'category',\n",
    "    }\n",
    "\n",
    "readopt_bank = pd.read_csv(\"../data/bank-additional-full.csv\",delimiter=\";\", dtype=column_types,\n",
    "                            #parse_dates=['date'],\n",
    "                            )\n",
    "bank['date'] = '2020-01-25'\n",
    "date = bank['date']\n",
    "readopt_bank['date'] = pd.to_datetime(date,format='%Y-%m-%d')\n",
    "\n",
    "print(mem_usage(readopt_bank))\n",
    "readopt_bank.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
