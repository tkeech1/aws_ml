{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2020/01/predict-electricity-consumption-time-series-analysis.html\n",
    "# Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader.data as data\n",
    "\n",
    "start_date = '2001-01-01'\n",
    "end_date = '2019-12-31'\n",
    "\n",
    "predictors = {\n",
    "    'sp500': {\n",
    "      'ticker': '^GSPC',\n",
    "    },\n",
    "    'gdax': {\n",
    "      'ticker': '^GDAXI',\n",
    "    },\n",
    "    'nikkei': {\n",
    "      'ticker': '^N225',\n",
    "    },\n",
    "    'gold': {\n",
    "      'ticker': 'GLD',\n",
    "    },\n",
    "    '10y_treasury': {\n",
    "      'ticker': '^TNX',\n",
    "    },\n",
    "    'APPL': {\n",
    "      'ticker': 'APPL',\n",
    "    },\n",
    "}\n",
    "\n",
    "for predictor in predictors:\n",
    "    predictors[predictor]['data'] = data.DataReader(predictors[predictor]['ticker'], 'yahoo', start_date, end_date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "drop_cols = ['High','Low','Open','Adj Close','Volume']\n",
    "\n",
    "for predictor in predictors:\n",
    "    predictors[predictor]['data_mod'] = predictors[predictor]['data'].rename(columns={\"Close\": predictor}, errors=\"raise\")\n",
    "    predictors[predictor]['data_mod'] = predictors[predictor]['data_mod'].drop(drop_cols, axis=1)\n",
    "    if df is None:\n",
    "        df = predictors[predictor]['data_mod']\n",
    "    else:     \n",
    "        df = df.join(predictors[predictor]['data_mod'], how='outer')\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/stock.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "col_dtypes = {\n",
    "    'sp500': np.float32,\n",
    "    'gdax': np.float32,\n",
    "    'nikkei': np.float32,\n",
    "    'gold': np.float32,\n",
    "    '10y_treasury': np.float32,\n",
    "}\n",
    "\n",
    "dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d')\n",
    "\n",
    "df = pd.read_csv('../data/stock.csv', parse_dates=['Date'], date_parser=dateparse, dtype=col_dtypes)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.line(df, x='Date', y='sp500')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "df_scaled = df.copy()\n",
    "#df_scaled.iloc[:,1:] = StandardScaler().fit_transform(df_scaled.iloc[:,1:])\n",
    "#df_scaled.iloc[:,1:] = np.log(df_scaled.iloc[:,1:])\n",
    "#df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "mode = 'lines'\n",
    "#mode = 'lines+markers'\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_scaled['Date'], y=df_scaled['sp500'],\n",
    "                    mode=mode,\n",
    "                    name='sp500'))\n",
    "fig.add_trace(go.Scatter(x=df_scaled['Date'], y=df_scaled['gdax'],\n",
    "                    mode=mode,\n",
    "                    name='gdax'))\n",
    "fig.add_trace(go.Scatter(x=df_scaled['Date'], y=df_scaled['gold'],\n",
    "                    mode=mode,\n",
    "                    name='gold'))\n",
    "fig.add_trace(go.Scatter(x=df_scaled['Date'], y=df_scaled['nikkei'],\n",
    "                    mode=mode,\n",
    "                    name='nikkei'))\n",
    "fig.add_trace(go.Scatter(x=df_scaled['Date'], y=df_scaled['10y_treasury'],\n",
    "                    mode=mode,\n",
    "                    name='10y_treasury'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.style.use('fivethirtyeight')\n",
    "#from pylab import rcParams\n",
    "#rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "def graph_stationarity(timeseries, column):\n",
    "    #Determing rolling statistics\n",
    "    rolmean = timeseries[column].rolling(100).mean()\n",
    "    rolstd = timeseries[column].rolling(100).std()\n",
    "    #Plot rolling statistics:\n",
    "    #plt.plot(timeseries, color='blue',label='Original')\n",
    "    #plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    #plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    #plt.legend(loc='best')\n",
    "    #plt.title('Rolling Mean and Standard Deviation')\n",
    "    #plt.show(block=False)\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=timeseries[column],\n",
    "                        mode=mode,\n",
    "                        name=column))\n",
    "    fig.add_trace(go.Scatter(y=rolmean,\n",
    "                        mode=mode,\n",
    "                        name='rollingmean'))\n",
    "    fig.add_trace(go.Scatter(y=rolstd,\n",
    "                        mode=mode,\n",
    "                        name='rollingstd'))\n",
    "    fig.show()\n",
    "\n",
    "def dickey_fuller(timeseries, column):\n",
    "    #perform dickey fuller test  \n",
    "    print(\"Results of Dickey Fuller test\")\n",
    "    adft = adfuller(timeseries[column],autolag='AIC')\n",
    "    # output for dft will give us without defining what the values are.\n",
    "    #hence we manually write what values does it explains using a for loop\n",
    "    output = pd.Series(adft[0:4],index=['Test Statistics','p-value','No. of lags used','Number of observations used'])\n",
    "    for key,values in adft[4].items():\n",
    "        output['critical value (%s)'%key] =  values\n",
    "    print(output)\n",
    "    \n",
    "graph_stationarity(df, 'sp500')\n",
    "dickey_fuller(df, 'sp500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data stationary\n",
    "# first take the log \n",
    "# the calculate a rolling mean and stddev\n",
    "\n",
    "moving_avg = df_scaled.rolling(100).mean()\n",
    "std_dev = df_scaled.rolling(100).std()\n",
    "\n",
    "moving_avg.tail(14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the difference of the series and the mean at every point in the series.\n",
    "\n",
    "df_log_moving_avg_diff = df_scaled.drop(['Date'],axis=1) - moving_avg\n",
    "df_log_moving_avg_diff.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_log_moving_avg_diff, y='sp500')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_stationarity(df_log_moving_avg_diff, 'sp500')\n",
    "dickey_fuller(df_log_moving_avg_diff, 'sp500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_average = df_scaled.ewm(halflife=365, min_periods=0, adjust=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logScale_weightedMean = df_scaled.drop(['Date'], axis=1)-weighted_average\n",
    "graph_stationarity(logScale_weightedMean, 'sp500')\n",
    "dickey_fuller(df_log_moving_avg_diff, 'sp500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use differencing instead\n",
    "df_scaled_diff = df_scaled - df_scaled.shift()\n",
    "df_scaled_diff.dropna(inplace=True)\n",
    "graph_stationarity(df_scaled_diff,'sp500')\n",
    "dickey_fuller(df_scaled_diff,'sp500')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
